Data Science Research Methods: Python Edition - Course Notes
============
February 2019
Chris Cameron

I am auditing [Microsoft Professional Program for Artificial Intelligence track](https://academy.microsoft.com/en-us/tracks/artificial-intelligence/).

The fitth of 10 courses is [Data Science Research Methods: Python Edition](https://courses.edx.org/courses/course-v1:Microsoft+DAT273x+1T2019/courseware/9a27d5b6-48c4-1194-3afa-cf0232935159/8f6609c4-212c-a8bf-7283-d22e85998cc9/).

# Introduction

The Jupyter Notebooks for the labs are [here](https://github.com/MicrosoftLearning/Research-Methods-for-Data-Science-with-Python)

# The Research Process

## The Research Process

### Goals of Research

1. Question Development, with Analytics in mind
2. Collecting data for the question you want to answer
  - straight analytics you already have the data sources, but you might not like the variables
  - in research, you get to find the data you need to answer your question
3. Dynamic, iterative problem-solving process

Process
- frame the question
- form a theory
- form a hypothesis
- design an experiment / study and test
- draw conclusions; repeat as necessary
- final conclusion

Goals for you (me) in the course
- when given _data out of context_, you can be more effective
- _prevent data misuse_; not all data are created equal
- know _when to recommend_ data collection
_ can design your own research

### Goals of Research Part 2

**Basic Reasearch**

- describe / explain / predict / control (these are the subtypes)
- goal: understand X
  - how does x work
  - why do customers do x
- advantage: planning next moves
- about understanding your topic
- doesn't allow us to "make new moves"

**Applied Research**

- evaluation of practice, product, idea, assumption
- choices often made based on _assumptions_ or _intuition_
- be right. stand on firm ground!
- a way to test assumptions
- could be smaller scale tests, shorter, tests

### The Circle of Science

1. Theory: detailed explanation of how something works
2. Hypothesis: what i should expect to see if theory is true
3. Data Collection: use appropriate research methods
4. Descriptive Statistics: is my hypothesis suported _in my sample_?
5. Inferential Statistics: If so, can I reject 'chance' as an explanation and generalize to the population?
6. Draw Conclusions: implications for Theory and Methods
7. back to 1!

### Clarifying the Questions

Common Problem: overstuff a survey
- we want to know everything

Problem: depth(quality) vs breadth

Clarifying Interview
- uncover the 'question behind the question'
- re-imagining the project around that

goal
- 1-2 learning objectives
- several lines of attack for those objectives
- tight focus on key objectives

Research Foxtrot
1. Look at proposed design. Step back. What are underlying assumptions and questions?
2. Formalize that (theory)
3. Identify focused several lines of attack (hypotheses) ways of testing that theory
4. Develop study / survey around those

## The Psychology of Providing Data

### The Psychology of Providing Data - Part 1

Participants are people.
- not robots giving info
- biased!
- influenced by design decisions

People want to manage their impressions of you and themselves

Rule 1: Be NEUTRAL. If you say "how often do you recycle?" they'll say "ALL THE TIME!" because they want to feel good

Rule 2: Sound Objective, because people are really good at knowing what answer you're looking for. Some want to sabotage you, others want to co-operate.

### The Psychology of Providing Data - Part 2

People do not know _why_ they do things and will _make up_ answers when asked.

People are biased by the order of things.

Especially with "why?" questions, people make things up.

more generally: avoid more complex questions.

goal for survey questions: you want Simple and Knowable questions. If people can't "gut" know the answer to it, don't ask them.

### The Psychology of Providing Data - Part 3

Placebo Effects

- Beliefs matter. e.g., products are _more effective_ when people think they are.
- manage expectations. if something is more expensive, they assume it's better

Observer bias: see what you want to see
Observer effect: act differently when observed

Solution: Blinding

neither participants, _nor people collecting the data_, should know what to expect.

if you expose people to words about the elderly, people appeared to walk away slowly. so then they didn't tell the observers what the study was about and the difference went away.

double-blind is best

## Knowledge Check

### Knowledge Check

not available

# Planning for Analysis

## Planning for Analysis

### Samples vs Populations



### Null Hypothesis

### Discrediting the Null Hypothesis - P Values

### Discrediting the Null Hypothesis - Confidence Intervals

## Power for Sample Size Planning

### Power Part 1

### Power Part 2

### Sample Size Planning

## Research Practices

### False Positives - False Negatives

### Questionable Research Practices

## Knowledge Check

### Knowledge Check

## Lab

### Module 2 Lab

### Lab Check

# Research Claims

# Measurement

# Correlation and Experimental Designs
